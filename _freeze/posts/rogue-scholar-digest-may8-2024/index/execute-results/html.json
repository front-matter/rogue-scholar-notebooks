{
  "hash": "4a8edc5285d8c7a653ad7e8819963827",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Rogue Scholar Digest May 8, 2024\"\ndescription: |\n  This is a summary of the Rogue Scholar blog posts published April 24 - May 7, 2024.\ndate: 2024-05-08\ncategories: [\"digest\"]\nimage: \"/images/2024-04-24-footer.png\"\n---\n\n::: {#c0f2c38f .cell execution_count=1}\n``` {.python .cell-code}\nimport requests\nimport locale\nimport re\nfrom typing import Optional\nimport datetime\nfrom IPython.display import Markdown\n\nlocale.setlocale(locale.LC_ALL, \"en_US\")\nbaseUrl = \"https://api.rogue-scholar.org/\"\npublished_since = \"2024-04-24\"\npublished_until = \"2024-05-07\"\nfeature_image = 1\ninclude_fields = \"title,authors,published_at,summary,blog_name,blog_slug,doi,url,image\"\nurl = (\n    baseUrl\n    + f\"posts?&published_since={published_since}&published_until={published_until}&language=en&sort=published_at&order=asc&per_page=50&include_fields={include_fields}\"\n)\nresponse = requests.get(url)\nresult = response.json()\n\n\ndef get_post(post):\n    return post[\"document\"]\n\n\ndef format_post(post):\n    doi = post.get(\"doi\", None)\n    url = f\"[{doi}]({doi})\\n<br />\" if doi else \"\"\n    title = f\"[{post['title']}]({doi})\" if doi else f\"[{post['title']}]({post['url']})\"\n    published_at = datetime.datetime.utcfromtimestamp(post[\"published_at\"]).strftime(\n        \"%B %-d, %Y\"\n    )\n    blog = f\"[{post['blog_name']}](https://rogue-scholar.org/blogs/{post['blog_slug']})\"\n    author = \", \".join([f\"{x['name']}\" for x in post.get(\"authors\", None) or []])\n    summary = post[\"summary\"]\n    return f\"### {title}\\n{url}Published {published_at} in {blog}<br />{author}<br />{summary}\\n\"\n\n\nposts = [get_post(x) for i, x in enumerate(result[\"hits\"])]\nposts_as_string = \"\\n\\n\".join([format_post(x) for x in posts])\n\ndef doi_from_url(url: str) -> Optional[str]:\n    \"\"\"Return a DOI from a URL\"\"\"\n    match = re.search(\n        r\"\\A(?:(http|https)://(dx\\.)?(doi\\.org|handle\\.stage\\.datacite\\.org|handle\\.test\\.datacite\\.org)/)?(doi:)?(10\\.\\d{4,5}/.+)\\Z\",\n        url,\n    )\n    if match is None:\n        return None\n    return match.group(5).lower()\n\nimages = [x[\"image\"] for x in posts if x.get(\"image\", None) is not None]\nimage = images[feature_image]\nmarkdown = f\"![]({image})\\n\\n\"\nmarkdown += posts_as_string\nMarkdown(markdown)\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=4}\n![](https://tzovar.as/assets/images/2024-04-24-footer.png)\n\n### [An update on the Scholars on Twitter dataset](https://doi.org/10.59350/abapf-y4f53)\n[https://doi.org/10.59350/abapf-y4f53](https://doi.org/10.59350/abapf-y4f53)\n<br />Published April 24, 2024 in [Leiden Madtrics](https://rogue-scholar.org/blogs/leidenmadtrics)<br />Philippe Mongeon, Timothy D. Bowman, Rodrigo Costas, Wenceslao Arroyo-Machado<br /><strong>\n Introduction\n</strong>\nOn August 21, 2022, we made available the first version of our dataset of scholars on Twitter created with two open data sources: Crossref Event Data and OpenAlex.\n\n\n### [Automating data exports from Apple Health](https://doi.org/10.59350/cap2n-agh49)\n[https://doi.org/10.59350/cap2n-agh49](https://doi.org/10.59350/cap2n-agh49)\n<br />Published April 24, 2024 in [Bastian Greshake Tzovaras](https://rogue-scholar.org/blogs/tzovar)<br />Bastian Greshake Tzovaras<br />The dynamic footer of my website has been powered by a little aggregation of some of my personal data for about 5 1/2 years by now. Until recently, all the data related to my activity and physiology (steps, heart rate, sleep, body) came from an Oura Ring.\n\n\n### [Markov Chain Monte What?](https://doi.org/10.59350/mxfyk-6av39)\n[https://doi.org/10.59350/mxfyk-6av39](https://doi.org/10.59350/mxfyk-6av39)\n<br />Published April 25, 2024 in [Bayesically Speaking](https://rogue-scholar.org/blogs/bayesically_speaking)<br />Matías Castillo-Aguilar<br /><strong>\n Introduction\n</strong>\nAlright, folks, let’s dive into the wild world of statistics and data science! Picture this: you’re knee-deep in data, trying to make sense of the chaos.\n\n\n### [The courage to discuss](https://doi.org/10.59350/bjh0z-gw219)\n[https://doi.org/10.59350/bjh0z-gw219](https://doi.org/10.59350/bjh0z-gw219)\n<br />Published April 25, 2024 in [Chris Hartgerink](https://rogue-scholar.org/blogs/chjh)<br />Chris Hartgerink<br />I want to recommit to writing, to recommit to actively and publicly think about what is happening. I want to recommit to the idea that thoughts are dynamic and never settled — that thinking in public helps move away from sharing only finalized arguments. Thoughts are produced and reproduced through the conversations we have, be it directly on the phone or indirectly through writing and reading.\n\n\n### [DNA Day Launch for Hong Kong’s Moonshot for Biology](https://doi.org/10.59350/eemcp-h8f94)\n[https://doi.org/10.59350/eemcp-h8f94](https://doi.org/10.59350/eemcp-h8f94)\n<br />Published April 25, 2024 in [GigaBlog](https://rogue-scholar.org/blogs/gigablog)<br />Scott Edmunds<br /><em>\n The first emblematic species sequenced by the Hong Kong Biodiversity Genomics Consortium are published to coincide with International DNA Day.\n</em>\n\n\n### [Molecular Symmetry Analysis Made Easy](https://doi.org/10.59350/s4ctj-7k667)\n[https://doi.org/10.59350/s4ctj-7k667](https://doi.org/10.59350/s4ctj-7k667)\n<br />Published April 25, 2024 in [Corin Wagen](https://rogue-scholar.org/blogs/cwagen)<br />Corin Wagen<br />Pure mathematics has all sorts of unexpected connections to other fields, and chemistry is no exception.\n\n\n### [The MHONGOOSE survey of atomic gas in and around galaxies](https://doi.org/10.59350/686jg-5dh08)\n[https://doi.org/10.59350/686jg-5dh08](https://doi.org/10.59350/686jg-5dh08)\n<br />Published April 26, 2024 in [Triton Station](https://rogue-scholar.org/blogs/tritonstation)<br />Stacy McGaugh<br />I have been spending a lot of time lately writing up a formal paper on high redshift galaxies, so haven’t had much time to write here. The paper is a lot more involved than I told you so, but yeah, I did. Repeatedly. I do have a start on a post on self-interacting dark matter that I hope eventually to get back to. Today, I want to give a quick note about the MHONGOOSE survey. But first, a non-commercial interruption.\n\n\n### [Five Years of Economics from the Top Down](https://doi.org/10.59350/8a58k-yg969)\n[https://doi.org/10.59350/8a58k-yg969](https://doi.org/10.59350/8a58k-yg969)\n<br />Published April 27, 2024 in [Economics from the Top Down](https://rogue-scholar.org/blogs/etd)<br />Blair Fix<br />My how time flies. As of April 11th, 2024, I’ve been blogging for five years. To celebrate, I thought I’d engage in some obligatory naval gazing. Why blog? I started this blog on a whim. In the spring of 2019, I was one year post PhD and busy publishing pieces of my dissertation. It was about as much fun as licking sandpaper. The problem, I now realize, is that I hate academic writing.\n\n\n### [Atlantal ribs of the Carnegie <i>Diplodocus</i>, Moscow and Vienna casts](https://doi.org/10.59350/0ezp4-a1h55)\n[https://doi.org/10.59350/0ezp4-a1h55](https://doi.org/10.59350/0ezp4-a1h55)\n<br />Published April 27, 2024 in [Sauropod Vertebra Picture of the Week](https://rogue-scholar.org/blogs/svpow)<br />Mike Taylor<br />Eighteen months ago, I noted that the Carnegie Museum’s\n<em>\n Diplodocus\n</em>\nmount has no atlantal ribs (i.e. ribs of the first cervical vertebra, the atlas). But that the Paris cast has long atlantal ribs — so long the extend past the posterior end of the axis.  There were two especially provocative comments to that post. First, Konstantin linked to a photo of the Russian cast (first mounted in St. Petersburg but currently residing in Moscow).\n\n\n### [Large Language Models for Code Writing: Security Assessment](https://doi.org/10.59350/c9qeh-m6z87)\n[https://doi.org/10.59350/c9qeh-m6z87](https://doi.org/10.59350/c9qeh-m6z87)\n<br />Published April 28, 2024 in [Stories by Research Graph on Medium](https://rogue-scholar.org/blogs/researchgraph)<br />Xuzeng He<br />Latest effort in assessing the security of the code generated by large language models Author   · Xuzeng He (\n<strong>\n ORCID:\n</strong>\n0009–0005–7317–7426) Introduction   With the surge of Large Language Models (LLMs) nowadays, there is a rising trend among developers to use Large Language Models to assist their daily code writing. Famous products include GitHub Copilot or simply ChatGPT.\n\n\n### [\"I put the ways of childhood behind me\" — my remembrance of Dan Dennett](https://doi.org/10.59350/17mxp-ng136)\n[https://doi.org/10.59350/17mxp-ng136](https://doi.org/10.59350/17mxp-ng136)\n<br />Published April 29, 2024 in [Quintessence of Dust](https://rogue-scholar.org/blogs/sfmatheson)<br />Stephen Matheson<br />For five years through 2018, our humanist community, the Humanist Hub*, met every Sunday afternoon at our suite in Harvard Square for fellowship, music, and a speaker. Our advisory board included luminaries of humanism such as Rebecca Goldstein, Steven Pinker, and Dan Dennett. These friends of the organization regularly spoke at Humanist Hub events.\n\n\n### [Commonmeta grows up](https://doi.org/10.53731/zkrxq-mj859)\n[https://doi.org/10.53731/zkrxq-mj859](https://doi.org/10.53731/zkrxq-mj859)\n<br />Published April 29, 2024 in [Front Matter](https://rogue-scholar.org/blogs/front_matter)<br />Martin Fenner<br />The Commonmeta standard for scholarly metadata continues towards version 1.0 with some important changes in version v0.14, released this week. And metadata for all DOIs from Crossref and DataCite can now be retrieved in commonmeta format via a new web service.\n\n\n### [Multimodal Large Language Models for Misinformation Detection and Reasoning](https://doi.org/10.59350/mtep9-gwy69)\n[https://doi.org/10.59350/mtep9-gwy69](https://doi.org/10.59350/mtep9-gwy69)\n<br />Published April 29, 2024 in [Stories by Research Graph on Medium](https://rogue-scholar.org/blogs/researchgraph)<br />Wenyi Pi<br />Exploring innovative Strategies in Combating Misinformation with Enhanced Multimodal Understanding  Author  Wenyi Pi (\n<strong>\n ORCID\n</strong>\n: 0009–0002–2884–2771) Introduction   Misinformation refers to false or inaccurate information that is often given to someone in a deliberate attempt to make them believe something that is not true. This has a significantly negative impact on public health, political stability and social trust and harmony.\n\n\n### [RAG 2.0 is Coming?](https://doi.org/10.59350/6frhg-zxp80)\n[https://doi.org/10.59350/6frhg-zxp80](https://doi.org/10.59350/6frhg-zxp80)\n<br />Published April 30, 2024 in [Stories by Research Graph on Medium](https://rogue-scholar.org/blogs/researchgraph)<br />Qingqin Fang<br />A Unified and Collaborative Framework for LLM  Author   · Qingqin Fang (\n<strong>\n ORCID:\n</strong>\n0009–0003–5348–4264) Introduction   In today’s rapidly evolving field of artificial intelligence, large language models (LLMs) are demonstrating unprecedented potential. Particularly, the Retrieval-Augmented Generation (RAG) architecture has become a hot topic in AI technology due to its unique technical capabilities.\n\n\n### [RNNs vs GRUs vs LSTMs](https://doi.org/10.59350/t6mga-7zd77)\n[https://doi.org/10.59350/t6mga-7zd77](https://doi.org/10.59350/t6mga-7zd77)\n<br />Published April 30, 2024 in [Stories by Research Graph on Medium](https://rogue-scholar.org/blogs/researchgraph)<br />Dhruv Gupta<br /><strong>\n The Three Oldest Pillars of NLP\n</strong>\nAuthor  Dhruv Gupta (\n<strong>\n ORCID\n</strong>\n: 0009–0004–7109–5403) Introduction   Natural Language Processing (NLP) has almost become synonymous with Large Language Models (LLMs), Generative AI, and fancy chatbots. With the ever-increasing amount of textual data and exponential growth in computational knowledge, these models are improving every day.\n\n\n### [Detecting anomeric effects in tetrahedral boron bearing four oxygen substituents.](https://doi.org/10.59350/dybzk-cs537)\n[https://doi.org/10.59350/dybzk-cs537](https://doi.org/10.59350/dybzk-cs537)\n<br />Published April 30, 2024 in [Henry Rzepa's Blog](https://rogue-scholar.org/blogs/rzepa)<br />Henry Rzepa<br />In an earlier post, I discussed[1] a phenomenon known as the “anomeric effect” exhibited by tetrahedral carbon compounds with four C-O bonds. Each oxygen itself bears two bonds and has two lone pairs, and either of these can align with one of three other C-O bonds to generate an anomeric effect. Here I change the central carbon to a boron to explore what happens, as indeed I promised earlier.\n\n\n### [The <i>Brachiosaurus altithorax</i> holotype FMNH PR 25107 in the ground](https://doi.org/10.59350/tfx7z-p1v71)\n[https://doi.org/10.59350/tfx7z-p1v71](https://doi.org/10.59350/tfx7z-p1v71)\n<br />Published May 1, 2024 in [Sauropod Vertebra Picture of the Week](https://rogue-scholar.org/blogs/svpow)<br />Mike Taylor<br />I was cleaning out my Downloads directory — which, even after my initial forays, still accounts for 11 Gb that I really need to reclaim from my perptually almost-full SSD. And I found this beautiful image under the filename\n<strong>\n csgeo4028.jpeg\n</strong>\n.\n<em>\n Brachiosaurus altithorax\n</em>\nholotype FMNH PR 25107 during excavation. The thing is, I have no idea where this image came from.\n\n\n### [JOSSCast #9: Reproducibility in Neuroscience – Mats van Es on FieldTrip reproducescript](https://doi.org/10.59349/4pk73-a2h25)\n[https://doi.org/10.59349/4pk73-a2h25](https://doi.org/10.59349/4pk73-a2h25)\n<br />Published May 2, 2024 in [Journal of Open Source Software Blog |](https://rogue-scholar.org/blogs/joss)<br />Arfon M. Smith<br /><strong>\n Subscribe Now:\n</strong>\nApple, Spotify, YouTube, RSS  Mats van Es joins Arfon and Abby to discuss reproducible science and the functionality he added to FieldTrip, a MATLAB software toolbox for analyzing brain imaging data. Mats is a cognitive neuroscientist at the University of Oxford. You can follow Mats on Twitter/X @mats_van_es.\n\n\n### [Calculating birthday probabilities with R instead of math](https://doi.org/10.59350/r419r-zqj73)\n[https://doi.org/10.59350/r419r-zqj73](https://doi.org/10.59350/r419r-zqj73)\n<br />Published May 3, 2024 in [Andrew Heiss's blog](https://rogue-scholar.org/blogs/andrewheiss)<br />Andrew Heiss<br />Even though I’ve been teaching R and statistical programming since 2017, and despite the fact that I do all sorts of heavily quantitative research,\n<em>\n I’m really really bad at probability math\n</em>\n.  Like super bad. The last time I truly had to do set theory and probability math was in my first PhD-level stats class in 2012.\n\n\n### [The Flowdown #1](https://dualpower.supply/posts/flowdown-1)\nPublished May 3, 2024 in [Dual Power Supply](https://rogue-scholar.org/blogs/dualpower)<br />Kirk Pollard Smith<br />I sip slowly from the information firehouse that is my cornucopia of industry newsletters, RSS feeds, and Google Scholar updates on new publications in the flow battery landscape. There’s not enough time to give everything a proper read, and often if I see something useful I just file it away in Zotero for it to collect digital dust.\n\n\n### [The Potter Creek <i>Brachiosaurus</i> humerus, in various states of repair](https://doi.org/10.59350/rhh6a-m8195)\n[https://doi.org/10.59350/rhh6a-m8195](https://doi.org/10.59350/rhh6a-m8195)\n<br />Published May 5, 2024 in [Sauropod Vertebra Picture of the Week](https://rogue-scholar.org/blogs/svpow)<br />Mike Taylor<br />As iconic as\n<em>\n Brachiosaurus altithorax\n</em>\nis, it’s known from surprisingly little material.\n\n\n### [Archiving scholarly blogs with Rogue Scholar](https://doi.org/10.59350/pp903-gve38)\n[https://doi.org/10.59350/pp903-gve38](https://doi.org/10.59350/pp903-gve38)\n<br />Published May 6, 2024 in [Bastian Greshake Tzovaras](https://rogue-scholar.org/blogs/tzovar)<br />Bastian Greshake Tzovaras<br />The pews of the\n<i>\n Internet Archive\n</i>\nback in 2018.\n<strong>\n tl;dr: Posts on this blog are now automatically archived, indexed and full-text searchable through\n <em>\n  The Rogue Scholar\n </em>\n</strong>\n.  The jury might still be out on whether the\n<em>\n small\n</em>\nor\n<em>\n indie\n</em>\nweb will make a comeback, but I’ve personally enjoyed posting more on my blog here in recent months.\n\n\n### [Are Large Language Models Our Allies or Enemies in the Fight Against Fake News?](https://doi.org/10.59350/st0jr-ad818)\n[https://doi.org/10.59350/st0jr-ad818](https://doi.org/10.59350/st0jr-ad818)\n<br />Published May 7, 2024 in [Stories by Research Graph on Medium](https://rogue-scholar.org/blogs/researchgraph)<br />Amanda Kau<br />Large Language Models for Fake News Generation and Detection  Author  Amanda Kau (\n<strong>\n ORCID\n</strong>\n: 0009–0004–4949–9284) Introduction   In recent years, fake news has become an increasing concern for many, and for good reason. Newspapers, which we once trusted to deliver credible news through accountable journalists, are vanishing en masse along with their writers.\n\n\n### [Transformers Models in NLP](https://doi.org/10.59350/c7nrg-xay43)\n[https://doi.org/10.59350/c7nrg-xay43](https://doi.org/10.59350/c7nrg-xay43)\n<br />Published May 7, 2024 in [Stories by Research Graph on Medium](https://rogue-scholar.org/blogs/researchgraph)<br />Dhruv Gupta<br />Attention mechanism not getting enough attention  Author  Dhruv Gupta (\n<strong>\n ORCID\n</strong>\n: 0009–0004–7109–5403) Introduction   As discussed in this article, RNNs were incapable of learning long-term dependencies. To solve this issue both LSTMs and GRUs were introduced. However, even though LSTMs and GRUs did a fairly decent job for textual data they did not perform well.\n\n\n### [Fine-tuning Large Language Models: A Brief Introduction](https://doi.org/10.59350/1aezq-kk827)\n[https://doi.org/10.59350/1aezq-kk827](https://doi.org/10.59350/1aezq-kk827)\n<br />Published May 7, 2024 in [Stories by Research Graph on Medium](https://rogue-scholar.org/blogs/researchgraph)<br />Xuzeng He<br />Supervised Fine-tuning, Reinforcement Learning from Human Feedback and the latest SteerLM  Author   · Xuzeng He (\n<strong>\n ORCID:\n</strong>\n0009–0005–7317–7426) Introduction   Large Language Models (LLMs), usually trained with extensive text data, can demonstrate remarkable capabilities in handling various tasks with state-of-the-art performance. However, people nowadays typically want something more personalised instead of a general solution.\n\n\n### [Three Paradigms of RAG](https://doi.org/10.59350/5j7tt-5y328)\n[https://doi.org/10.59350/5j7tt-5y328](https://doi.org/10.59350/5j7tt-5y328)\n<br />Published May 7, 2024 in [Stories by Research Graph on Medium](https://rogue-scholar.org/blogs/researchgraph)<br />Vaibhav Khobragade<br /><strong>\n From Naive to Modular: Tracing the Evolution of Retrieval-Augmented Generation\n</strong>\nAuthor   · Vaibhav Khobragade (\n<strong>\n ORCID:\n</strong>\n0009–0009–8807–5982) Introduction   Large Language Models (LLMs) have achieved remarkable success.\n\n\n### [Brief Introduction to the History of Large Language Models (LLMs)](https://doi.org/10.59350/m4c7t-epg97)\n[https://doi.org/10.59350/m4c7t-epg97](https://doi.org/10.59350/m4c7t-epg97)\n<br />Published May 7, 2024 in [Stories by Research Graph on Medium](https://rogue-scholar.org/blogs/researchgraph)<br />Wenyi Pi<br />Understanding the Evolutionary Journey of LLMs  Author  Wenyi Pi (\n<strong>\n ORCID\n</strong>\n: 0009–0002–2884–2771) Introduction   When we talk about large language models (LLMs), we are actually referring to a type of advanced software that can communicate in a human-like manner. These models have the amazing ability to understand complex contexts and generate content that is coherent and has a human feel.\n\n\n### [The longer the context, the better? Unlimited Context Length in Megalodon](https://doi.org/10.59350/dx6a6-yy475)\n[https://doi.org/10.59350/dx6a6-yy475](https://doi.org/10.59350/dx6a6-yy475)\n<br />Published May 7, 2024 in [Stories by Research Graph on Medium](https://rogue-scholar.org/blogs/researchgraph)<br />Qingqin Fang<br />An improvement architecture superior to the Transformer, proposed by Meta  Author   · Qingqin Fang (\n<strong>\n ORCID:\n</strong>\n0009–0003–5348–4264) Introduction   Recently, researchers from Meta and the University of Southern California have introduced a model called Megalodon. They claim that this model can expand the context window of language models to handle millions of tokens without overwhelming your memory.\n\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}