---
title: Retraction Watch
description: |
  This notebook finds Rogue Scholar blog posts about the Retraction Watch 
  project using the Rogue Scholar API.
date: "2023-11-15"
bibliography: references.bib
format:
  html:
    toc: true
    code-fold: true
jupyter: python3
nocite: |
  @*
---

## Introduction

This notebook finds Rogue Scholar blog posts about the Retraction Watch project using the [Rogue Scholar API](https://api.rogue-scholar.org/posts). [Retraction Watch](https://retractionwatch.com/) reports on retractions of scientific papers. the project was started in 2010 by Ivan Oransky and Adam Marcus.

:::{.callout-note}
* We use the query `retraction watch`.
* We limit results to posts published since `2010` (the year Retraction Watch launched) and `en` as language.
* We retrieve the `title`, `authors`, `publication date`, `abstract`, `blog name`, `blog_slug`, and `doi`
* We sort the results in reverse chronological order (newest first)
:::

```{python}

import requests
import locale
import re
from typing import Optional
import pydash as py_
import datetime
from IPython.display import Markdown
locale.setlocale(locale.LC_ALL, "en_US")
baseUrl = "https://api.rogue-scholar.org/"
query = "retraction watch"
published_since = "2010"
featured_image = 0
curated = [1,2,3,9,12,16]

include_fields = "title,authors,published_at,summary,blog_name,blog_slug,doi,url,image"
url = baseUrl + f"posts?query={query.replace(' ', '+')}&published_since=2010&language=en&sort=published_at&order=desc&per_page=50&include_fields={include_fields}"
response = requests.get(url)
result = response.json()

def get_post(post):
    return post["document"]

def format_post(post):
    url = post.get("doi", None)
    url = f"[{url}]({url})\n<br />" if url else ""
    title = f"[{post['title']}]({url})"
    published_at = datetime.datetime.utcfromtimestamp(post["published_at"]).strftime("%B %-d, %Y")
    blog = f"[{post['blog_name']}](https://rogue-scholar.org/blogs/{post['blog_slug']})"
    author = ", ".join([ f"{x['name']}" for x in post.get("authors", None) or [] ])
    summary = post["summary"]
    return f"### {title}\n{url}Published {published_at} in {blog}<br />{author}<br /><br />{summary}\n"

posts = [ get_post(x) for i, x in enumerate(result["hits"]) if i not in curated]
posts_as_string = "\n".join([ format_post(x) for x in posts])

def doi_from_url(url: str) -> Optional[str]:
    """Return a DOI from a URL"""
    match = re.search(
        r"\A(?:(http|https)://(dx\.)?(doi\.org|handle\.stage\.datacite\.org|handle\.test\.datacite\.org)/)?(doi:)?(10\.\d{4,5}/.+)\Z",
        url,
    )
    if match is None:
        return None
    return match.group(5).lower()

# Get bibtex-formatted metadata for all posts
def get_bibtex(post):
    doi = doi_from_url(post["doi"])
    res = requests.get(baseUrl + "posts/" + doi + "?format=bibtex")
    return res.text

bibtex = "\n".join([ get_bibtex(x) for x in posts if x.get("doi", None) is not None ])
with open('references.bib', 'w') as f:
    f.write(bibtex)

images = [ x["image"] for x in posts if x.get("image", None) is not None ]
image = images[featured_image]
markdown = f"## Results\n![]({image})\n\n" + posts_as_string
Markdown(markdown)
```
### References

::: {#refs}
:::
